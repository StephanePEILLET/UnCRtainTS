{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3164b7-9501-431e-9d67-6807b9953832",
   "metadata": {},
   "source": [
    "# <center> Demo Inference </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c30082-a27c-4ef4-b323-c4b4929bdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import partial\n",
    "from omegaconf import DictConfig\n",
    "import os\n",
    "import torch\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "from typing import Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)   # ou FutureWarning, UserWarning, ...\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data.uncrtaints_adapter import UnCRtainTS_CIRCA_Adapter\n",
    "from dataloader_CIRCA_old.datasets.CIRCA_dataset_for_UnCRtainTS import CircaPatchDataSetForUnCRtainTS\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "os.chdir(os.path.join(os.getcwd(), \"model\"))\n",
    "\n",
    "from parse_args import create_parser\n",
    "from src.model_utils import get_model, load_checkpoint\n",
    "from src import utils\n",
    "from train_reconstruct import (\n",
    "    iterate,\n",
    "    prepare_output,\n",
    "    save_results,\n",
    "    seed_packages,\n",
    ")\n",
    "\n",
    "if os.getcwd().endswith(\"model\"):\n",
    "    os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8cc9718-66ec-43a0-bb16-618bf24cfcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_output(config):\n",
    "    os.makedirs(os.path.join(config.res_dir, config.experiment_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f22b64a5-86f9-4139-80ba-dd1afba17562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins pour faire l'inférence\n",
    "experiment_name = \"UnCRtainTS_bs_7_MGNLL_experiment\" \n",
    "res_dir = \"/DATA_10TB/data_rpg/outputs/UnCRtainTS/inference\"\n",
    "weight_folder = \"/DATA_10TB/data_rpg/outputs/UnCRtainTS/results/train\"\n",
    "\n",
    "parser = create_parser(mode=\"test\")\n",
    "test_config, _ = parser.parse_known_args()\n",
    "test_config.pid = os.getpid()\n",
    "test_config = OmegaConf.create(vars(test_config))\n",
    "assert test_config.get(\"sample_type\", False)\n",
    "\n",
    "# Récupération des paramètres issus du modèle \n",
    "NO_OVERWRITE = ['pid', 'device', 'resume_at', 'trained_checkp', 'res_dir', 'weight_folder', 'root1', 'root2', 'root3', 'max_samples_count', 'batch_size', 'display_step', 'plot_every', 'export_every', 'input_t', 'region', 'min_cov', 'max_cov']\n",
    "conf_path = os.path.join(weight_folder, experiment_name, \"conf.json\")\n",
    "model_config = OmegaConf.create(json.load(open(conf_path)))\n",
    "for key_to_delete in NO_OVERWRITE:\n",
    "    if model_config.get(key_to_delete, False):\n",
    "        model_config.pop(key_to_delete)\n",
    "# Mise à jour des paramètres de base du parser par les paramètres pris pour la création du modèle utilisé pour l'inférence \n",
    "test_config.update(model_config)\n",
    "test_config.update(\n",
    "    {\n",
    "        \"experiment_name\":experiment_name,\n",
    "        \"res_dir\": res_dir,\n",
    "        \"weight_folder\": weight_folder,\n",
    "    }\n",
    ")\n",
    "test_config = utils.str2list(test_config, [\"encoder_widths\", \"decoder_widths\", \"out_conv\"])\n",
    "config = OmegaConf.create(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11ffa0df-61d8-4ef0-b0d7-6939f0631336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAINABLE PARAMETERS: 635412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S1_LAUNCH: str = \"2014-04-03\"\n",
    "SEN12MSCRTS_SEQ_LENGTH: int = 30  # Length of the Sentinel time series\n",
    "CLEAR_THRESHOLD: float = 1e-3  # Threshold for considering a scene as cloud-free\n",
    "INPUT_T = 3 \n",
    "\n",
    "device = torch.device(config.device)\n",
    "config.use_sar = True\n",
    "prepare_output(config)\n",
    "\n",
    "model = get_model(config)\n",
    "model = model.to(device)\n",
    "config.N_params = utils.get_ntrainparams(model)\n",
    "print(f\"TOTAL TRAINABLE PARAMETERS: {config.N_params}\\n\")\n",
    "\n",
    "# instantiate tensorboard logger\n",
    "writer = SummaryWriter(os.path.join(config.res_dir, config.experiment_name))\n",
    "\n",
    "circa_ds = UnCRtainTS_CIRCA_Adapter(\n",
    "    phase=\"test\",\n",
    "    hdf5_file= \"/DATA_10TB/data_rpg/circa/hdf5/CIRCA_CR_merged.hdf5\",\n",
    "    shuffle=False,\n",
    "    use_sar=\"mix_closest\",\n",
    "    channels= \"all\",\n",
    "    compute_cloud_mask=False,\n",
    "    # paramaters specific to UnCRtainTS\n",
    "    cloud_masks= \"s2cloudless_mask\",\n",
    "    sample_type= \"cloudy_cloudfree\",\n",
    "    sampler= \"fixed\",\n",
    "    n_input_samples=INPUT_T,\n",
    "    rescale_method= \"default\",\n",
    "    min_cov= 0.0,\n",
    "    max_cov= 1.0,\n",
    "    ref_date= S1_LAUNCH,\n",
    "    seq_length=30, #TODO comment rendre cela adaptatif à la donnée ? \n",
    "    clear_threshold=CLEAR_THRESHOLD,\n",
    "    vary_samples=False, \n",
    ")\n",
    "\n",
    "dt_test = torch.utils.data.Subset(\n",
    "    circa_ds, range(0, min(config.max_samples_count, len(circa_ds)))\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dt_test, \n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    #collate_fn=circa_collate_fn  # Utiliser notre fonction personnalisée\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f4bd109-55d0-428c-b6a9-d4251fe1961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint /DATA_10TB/data_rpg/outputs/UnCRtainTS/results/train/UnCRtainTS_bs_7_MGNLL_experiment/model.pth.tar\n",
      "Loaded checkpoint with matching keys\n",
      "Testing . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                                                           | 2/594 [00:16<1:22:04,  8.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting . . .\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m _, test_img_metrics = \u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTest image metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_img_metrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cloud_reconstruction/UnCRtainTS_apo/model/train_reconstruct.py:340\u001b[39m, in \u001b[36miterate\u001b[39m\u001b[34m(model, data_loader, config, writer, mode, epoch, device)\u001b[39m\n\u001b[32m    337\u001b[39m errs, errs_se, errs_ae, vars_aleatoric = [], [], [], []\n\u001b[32m    339\u001b[39m t_start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcloudy_cloudfree\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1420\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1422\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1254\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/multiprocessing/connection.py:947\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    944\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    948\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m    949\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cr/lib/python3.11/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28mself\u001b[39m._selector.poll(timeout)\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "chckp_path = os.path.join(config.weight_folder, config.experiment_name, f\"model.pth.tar\")\n",
    "print(f\"Loading checkpoint {chckp_path}\")\n",
    "checkpoint = torch.load(chckp_path, map_location=config.device)[\"state_dict\"]\n",
    "\n",
    "try:  # try loading checkpoint strictly, all weights & their names must match\n",
    "    model.load_state_dict(checkpoint, strict=True)\n",
    "    print(\"Loaded checkpoint with matching keys\")\n",
    "except:\n",
    "    # rename keys\n",
    "    #   in_block1 -> in_block0, out_block1 -> out_block0\n",
    "    checkpoint_renamed = dict()\n",
    "    for key, val in checkpoint.items():\n",
    "        if \"in_block\" in key or \"out_block\" in key:\n",
    "            strs = key.split(\".\")\n",
    "            strs[1] = strs[1][:-1] + str(int(strs[1][-1]) - 1)\n",
    "            strs[1] = \".\".join([strs[1][:-1], strs[1][-1]])\n",
    "            key = \".\".join(strs)\n",
    "        checkpoint_renamed[key] = val\n",
    "    model.load_state_dict(checkpoint_renamed, strict=False)\n",
    "\n",
    "# Inference\n",
    "print(\"Testing . . .\")\n",
    "model.eval()\n",
    "\n",
    "_, test_img_metrics = iterate(\n",
    "    model,\n",
    "    data_loader=test_loader,\n",
    "    config=config,\n",
    "    writer=writer,\n",
    "    mode=\"test\",\n",
    "    epoch=1,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"\\nTest image metrics: {test_img_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e311a3-5091-4792-a3a4-8833ff172418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55760107-54b4-4606-8d58-48c1a92ee935",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Code obsolète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729ba2b-6320-4f0c-baf4-50265ca6938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins pour faire l'inférence\n",
    "# experiment_name = \"UnCRtainTS_bs_7_MGNLL_experiment\" \n",
    "# res_dir = \"/DATA_10TB/data_rpg/outputs/UnCRtainTS/inference\"\n",
    "# weight_folder = \"/DATA_10TB/data_rpg/outputs/UnCRtainTS/results/train\"\n",
    "\n",
    "# parser = create_parser(mode=\"test\")\n",
    "# test_config, _ = parser.parse_known_args()\n",
    "# test_config.pid = os.getpid()\n",
    "\n",
    "# print(test_config.sample_type)\n",
    "\n",
    "# conf_path = os.path.join(weight_folder, experiment_name, \"conf.json\")\n",
    "# print(conf_path)\n",
    "# if os.path.isfile(conf_path):\n",
    "#     with open(conf_path) as file:\n",
    "#         model_config = json.loads(file.read())\n",
    "#         t_args = argparse.Namespace()\n",
    "#         # do not overwrite the following flags by their respective values in the config file\n",
    "#         no_overwrite = [\n",
    "#             \"pid\",\n",
    "#             \"device\",\n",
    "#             \"resume_at\",\n",
    "#             \"trained_checkp\",\n",
    "#             \"res_dir\",\n",
    "#             \"weight_folder\",\n",
    "#             \"root1\",\n",
    "#             \"root2\",\n",
    "#             \"root3\",\n",
    "#             \"max_samples_count\",\n",
    "#             \"batch_size\",\n",
    "#             \"display_step\",\n",
    "#             \"plot_every\",\n",
    "#             \"export_every\",\n",
    "#             \"input_t\",\n",
    "#             \"region\",\n",
    "#             \"min_cov\",\n",
    "#             \"max_cov\",\n",
    "#         ]\n",
    "#         conf_dict = {\n",
    "#             key: val for key, val in model_config.items() if key not in no_overwrite\n",
    "#         }\n",
    "        \n",
    "#         for key, val in vars(test_config).items():\n",
    "#             if key in no_overwrite:\n",
    "#                 conf_dict[key] = val\n",
    "#         t_args.__dict__.update(conf_dict)\n",
    "#         config = OmegaConf.create(vars(t_args))\n",
    "#         config.update({\n",
    "#             \"experiment_name\":experiment_name,\n",
    "#             \"res_dir\": res_dir,\n",
    "#             \"weight_folder\": weight_folder,\n",
    "#         })\n",
    "        \n",
    "# else:\n",
    "#     config = test_config  # otherwise, keep passed flags without any overwriting\n",
    "# config = utils.str2list(config, [\"encoder_widths\", \"decoder_widths\", \"out_conv\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
